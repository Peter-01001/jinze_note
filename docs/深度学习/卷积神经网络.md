# 卷积神经网络

卷积神经网络（Convolutional Neural Network）CNN

## 引言

传统神经网络适合做2D、结构化数据

考虑3D情况点与点之间关系需要卷积神经网络以窗口提取特征

## 整体架构

+ **输入层**：没什么好说的

+ **卷积层**：提取特征

+ **池化层**：卷积层解决图像任务中的关键问题，让模型更高效、更鲁棒

+ **全连接层**：$y=wX+b$

### 卷积层

+ **卷积核（Convolutional Kernel）**：相当于卷积层的权重

Input(7×7×3)    Filter(3×3×3)

输入通道数和卷积核的通道数相同

+ **卷积过程**：输入数据滑动窗口后与卷积核算内积，一个卷积核对应一个特征图对应一个特征

+ **滑动窗口单位（步长/stride）**：越小越好一般为1，越大得到的单张特征图的像素元素数量越少

+ **下采样**：下采样就是对特征图做 “维度压缩” 的操作，核心目标是减小特征图的宽 / 高（通道数一般不变），降低数据量和计算成本，同时实现特征的浓缩与鲁棒性提升
下采样没有固定的运算规则，只要能实现特征图宽 / 高缩小的操作，都属于下采样

+ **卷积核越小越好**：N卡对3×3最好

+ **感受野**：卷积可以做多次，随着层数越深入，特征越全局

+ **边缘填充**：卷积核的边缘填充，填充0不影响结果

+ **卷积计算结果公式**：
  长度：$H_2 = \frac{H_1 - F_H + 2P}{s} + 1$

  宽度：$W_2 = \frac{W_1 - F_W + 2P}{s} + 1$

| 参数 | 含义 |
| :------: | :------: |
| $H_1$ | 输入特征图的高度 |
| $W_1$ | 输入特征图的宽度 |
| $H_2$ | 输出特征图的高度 |
| $W_2$ | 输出特征图的宽度 |
| $F_H$ | 卷积核的高度 |
| $F_W$ | 卷积核的宽度 |
| $P$ | 边界填充的层数（输入特征图四周补0的层数，宽、高方向一致） |
| $s$ | 滑动窗口的步长（卷积核每次移动的像素跨度，宽、高方向一致） |

+ **卷积参数共享**：滑动窗口时卷积核不变，参数多训练难度大，每个卷积核有一个对应的偏置

+ [可视化展示](https://poloclub.github.io/)

### 池化层

特征图个数不变，改变特征图大小

输入 &emsp;&emsp;&emsp;&emsp;&emsp;  输出
224×224×64 --->  112×112×64

+ **最大池化**：选最大值，值越大越重要

### 残差连接

搭建 “快捷通道”，让输入信息绕过一层或多层网络直接传递到后续层

+ **核心公式**：$y = x + F(x)$
